# Building a basic Web Scraper

## Step-by-step guide to creating a basic web scraper and crawler

<b>Web Scraping</b> refers to the automated process of extracting data from web pages using software tools or scripts. Typically, the goal is to compile a dataset, conduct analysis or to performe research.
In this repository I have crafted a straightforward <b>Python</b> script that leverages the WebDriver and BeautyfulSoup libraries to gather book-related information from the "La Casa del Libro" website. 
</br>
To build this bot Web Scraper, it's essential to delineate its core components:
1. Web Crawling: This phase involves the retrieval of pertinent URLs of interest.
2. HTML Parsing: Here, we dissect the HTML structure of these pages and extract their content.
3. Data Extraction: The final step entails extracting the specific data of interest from the HTML code.

This project exemplifies the seamless integration of these components to facilitate data retrieval and analysis.